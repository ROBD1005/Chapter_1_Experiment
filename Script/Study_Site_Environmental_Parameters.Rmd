---
title: "Study Site Environmental Parameters"
output:
  pdf_document: default
  html_document: default
date: "2023-08-28"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(readr)
library(here)
library(tidyverse)
library(lubridate)
library(ggplot2)
library(ggpubr) 
library(ggspatial)
library(ggthemes)
library(gridExtra)
library(grid)
library(Hmisc)
library(oce)
library(ocedata)
library(nlme)
library(zoo)
library(sf)
library(suncalc)
library(extrafont)
```


# Study Site Map Oce Package 

```{r}
# Define study site coordinates and labels
center_lon <- -118.28599
center_lat <- 33.70679092
study_site <- data.frame(name = "Point Fermin Park Beach,\n       Los Angeles, CA",
                         lon = center_lon,
                         lat = center_lat)

# Define lonlim and latlim from bounding box coordinates
lonlim <- c(-118.5, -118.1)
latlim <- c(33.6, 34)

# Expand the limits by 1 degree on each side
expanded_lonlim <- lonlim + c(-1, 1)
expanded_latlim <- latlim + c(-1, 1)

# Define the corners of the expanded rectangle
expanded_rect_coords <- data.frame(
  longitude = c(min(expanded_lonlim), max(expanded_lonlim), max(expanded_lonlim), min(expanded_lonlim), min(expanded_lonlim)),
  latitude = c(min(expanded_latlim), min(expanded_latlim), max(expanded_latlim), max(expanded_latlim), min(expanded_latlim))
)

# Setup the plot
png(here::here("Output", "study_site_map.png"), width = 6, height = 6, units = 'in', res = 1200, family = "Times New Roman")
par(mar = c(3, 2, 2, 2), family = "Times New Roman")

# Create a base map
mapPlot(coastlineWorldFine, 
        longitudelim = lonlim, 
        latitudelim = latlim, 
        lonlabels = TRUE,
        latlabels = TRUE,
        geographical = 4,
        projection = "+proj=mill",
        col = "darkolivegreen3", 
        border = "black",
        clip = TRUE)

# Plot the polygon with the specified color
mapPolygon(expanded_rect_coords, col="cyan3", border=NA)
mapPolygon(coastlineWorldFine, col = "darkolivegreen3", border = "grey40")


# Add grid
mapGrid(dlongitude = 0.1, dlatitude = 0.1, col = "black", lty = 3)

# Overlay the study site with a clearly visible point
mapPoints(longitude = study_site$lon,
          latitude = study_site$lat,
          pch = 20, cex = 1.5, col = "orange")

# Add a clearly readable label for the study site
mapText(longitude = study_site$lon - 0.075,
        latitude = study_site$lat + 0.12,
        labels = study_site$name,
        cex = 0.9, col = "black", font = 2, adj = c(0, 0.5), family = "Times New Roman")

# Include a scale bar with enhanced visibility
mapScalebar(x = "topright", col = "black", cex = 0.7)

```

# Open Water SST and pH for a nearby site (Newport Beach Pier)

#Temperature Data from UCSD Shore Stations 1924-2023
 
Carter, Melissa L.; Flick, Reinhard E.; Terrill, Eric; Beckhaus, Elena C.; Martin, Kayla; Fey, Connie L.; Walker, Patricia W.; Largier, John L.; McGowan, John A. (2022). Shore Stations Program, Newport Beach - Balboa Pier. In Shore Stations Program Data Archive: Current and Historical Coastal Ocean Temperature and Salinity Measurements from California Stations. UC San Diego Library Digital Collections. https://doi.org/10.6075/J0GX4BCP

Temperature data provided by the Shore Stations Program sponsored at Scripps Institution of Oceanography by California Department of Parks and Recreation, Natural Resources Division,  Award# C1670003, and pH data provided by the Southern California Coastal Ocean Observing System.

pH Data 
# Temperature Histogram 

```{r}
# Read the CSV file
newport.temp <- read_csv(here("Data", "Site_Data", "NewportBeach_TEMP_1924-2023.csv"))

# Filter data using TEMP_FLAG 
# 0 = good data, 5 = data from another source, 6 = data from a different site
# NaN is used to indicate historical/missing data
filtered_temp_data <- newport.temp %>%
  filter(is.na(TEMP_FLAG) | TEMP_FLAG %in% c(0, 5, 6)) %>%
  filter(SURF_TEMP_C >= 9 & SURF_TEMP_C <= 26) %>%
  mutate(Date = as.Date(paste(YEAR, MONTH, DAY, sep = "-"))) %>% 
  filter(Date >= as.Date("2020-01-01") & Date <= as.Date("2024-01-01")) %>% 
  select(Date, Temperature=SURF_TEMP_C)

#Daily Mean Temperature
experimental_daily_temp_stats <- filtered_temp_data %>%
  group_by(Date) %>%
  summarise(Mean_Temp = mean(Temperature, na.rm = TRUE)) 

# Calculate the overall mean temperature
overall_mean_temp <- mean(experimental_daily_temp_stats$Mean_Temp, na.rm = TRUE)
#print the overall mean temperature and pH
print(paste("Overall mean temperature:", round(overall_mean_temp, 2), "°C"))

# Calculate the mean temperature for the duration of the experiment
experimental_dates_temp <- experimental_daily_temp_stats %>% 
  filter(Date >= as.Date("2022-08-01") & Date <= as.Date("2022-09-30"))
experimental_mean_temp <- mean(experimental_dates_temp$Mean_Temp, na.rm = TRUE)
#print the overall mean temperature and pH
print(paste("Experimental mean temperature:", round(experimental_mean_temp, 2), "°C"))

#Histogram of Daily Mean Temperature
histogram_temp <- ggplot(experimental_daily_temp_stats, aes(x=Mean_Temp)) +
  geom_vline(aes(xintercept=12), color="#FFA726", size=1) +
  geom_vline(aes(xintercept=14), color="#FFA726", size=1) +
  geom_vline(aes(xintercept=16), color="#FFA726", size=1) +
  geom_vline(aes(xintercept=18), color="#FFA726", size=1) +
  geom_vline(aes(xintercept=20), color="#FFA726", size=1) +
  geom_vline(aes(xintercept=22), color="#FFA726", size=1) +
  geom_vline(aes(xintercept=24), color="#FFA726", size=1) +
  geom_vline(aes(xintercept=26), color="#FFA726", size=1) +
  geom_histogram(binwidth = 0.5, fill = "#FFE0B2", color = "darkslategrey", alpha=0.5) +
  geom_vline(aes(xintercept=overall_mean_temp), color="#F57C00", linetype="dashed", size=1) +
  geom_vline(aes(xintercept=experimental_mean_temp), color="#F57C00", linetype="dotted", size=1) +
  scale_x_continuous(breaks = seq(12, 26, by = 2)) +
  labs(x = "Mean Sea Surface Temperature (°C)",
       y = "Frequency",
       title="") +
  theme_classic() +
  theme(text = element_text(family = "Times New Roman"),
        axis.title = element_text(size = 12),
        axis.text = element_text(size = 10))

# Output the histogram
print(histogram_temp)
```


```{r}
# Read and preprocess data
newportbeach.pH <- read_csv(here("Data", "Site_Data", "Newport_pH_2005-2024.csv"))[-1,]

filtered.newportbeach.pH <- newportbeach.pH %>%
  mutate(pH = sea_water_ph_reported_on_total_scale_salinity_corrected,
         time = as.POSIXct(time, format = "%Y-%m-%dT%H:%M:%SZ", tz = "UTC"), Date=as.Date(time)) %>%
  filter(sea_water_ph_reported_on_total_scale_salinity_corrected_qc_agg %in% 1,
         Date >= as.Date("2020-01-01") & Date <= as.Date("2024-01-01")) %>% 
  select(Date, time, pH)

#Daily Mean pH
experimental_daily_pH_stats <- filtered.newportbeach.pH %>%
  group_by(Date) %>%
  summarise(Mean_pH = mean(pH, na.rm = TRUE)) 

# Calculate the overall mean pH
overall_mean_pH <- mean(experimental_daily_pH_stats$Mean_pH, na.rm = TRUE)
#print the overall mean temperature and pH
print(paste("Overall mean pH:", round(overall_mean_pH, 2), "°C"))

# Calculate the mean pH for the duration of the experiment
experimental_dates_pH <- experimental_daily_pH_stats %>% 
  filter(Date >= as.Date("2022-08-01") & Date <= as.Date("2022-09-30"))
experimental_mean_pH <- mean(experimental_dates_pH$Mean_pH, na.rm = TRUE)
#print the overall mean temperature and pH
print(paste("Experimental mean pH:", round(experimental_mean_pH, 2), "°C"))

histogram_pH <- ggplot(experimental_daily_pH_stats, aes(x=Mean_pH)) +
  geom_vline(aes(xintercept=7.6), color="darkcyan", size=1) +
  geom_vline(aes(xintercept=7.9), color="darkcyan", size=1) +
  geom_vline(aes(xintercept=overall_mean_pH), color="cyan3", linetype="dashed", size=1) +
  #geom_vline(aes(xintercept=experimental_mean_pH), color="cyan3", linetype="dotted", size=1) +
  geom_histogram(binwidth = 0.05, fill = "cyan2", color = "darkslategrey", alpha =0.5) +
  scale_x_continuous(breaks = seq(7, 8.5, by = 0.1)) +
  labs(x = "Mean pH (total scale)",
       y = "Frequency",
       title="") +
  theme_classic() +
  theme(text = element_text(family = "Times New Roman"),
        axis.title = element_text(size = 12),
        axis.text = element_text(size = 10))

# Output the histogram
print(histogram_pH)

# Combine the plots vertically
combined_histograms <- histogram_temp / histogram_pH 
print(combined_histograms)

# Save the combined plot
ggsave(here::here("Output", "stacked_histograms.png"), combined_histograms, width = 6, height = 6, dpi = 1400)

```





```{r}
# Read the image
map_image <- readPNG(here::here("Output", "study_site_map.png"))

# Convert the image into a rasterGrob object
map_grob <- rasterGrob(map_image, interpolate = TRUE)

# Create an empty plot and add the image
map_plot <- ggplot() + 
  annotation_custom(map_grob, xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = Inf) +
  theme_void()

# Use the height ratio to define the relative heights in the grid arrangement
combined_plot <- grid.arrange(
  map_plot,
  arrangeGrob(histogram_temp, histogram_pH, nrow = 2),
  ncol = 2,
  widths = c(2.5, 1.5),  # You may need to adjust this based on the map's aspect ratio
  heights = c(2.5, 1.5)
)

# Print the combined plot to verify alignment
print(combined_plot)

# Save the combined plot
ggsave("stacked_timeseries.png", combined_plot, width = 8, height = 5, dpi = 1200)
```




```{r}
# Read the CSV file
newport.temp <- read_csv(here("Data", "Site_Data", "NewportBeach_TEMP_1924-2023.csv"))

# Filter data using TEMP_FLAG 
# 0 = good data, 5 = data from another source, 6 = data from a different site
# NaN is used to indicate historical/missing data
filtered_temp_data <- newport.temp %>%
  filter(is.na(TEMP_FLAG) | TEMP_FLAG %in% c(0, 5, 6)) %>%
  filter(SURF_TEMP_C >= 9 & SURF_TEMP_C <= 26) %>%
  mutate(DATE = as.Date(paste(YEAR, MONTH, DAY, sep = "-")))

# Calculate the 95% CI for daily temperature
daily_temp_stats <- filtered_temp_data %>%
  group_by(DATE) %>%
  summarise(
    Mean = mean(SURF_TEMP_C, na.rm = TRUE))

# Calculate the overall mean temperature
overall_mean_temp <- mean(filtered_temp_data$SURF_TEMP_C, na.rm = TRUE)

#print the overall mean temperature and pH
print(paste("Overall mean temperature:", round(overall_mean_temp, 2), "°C"))

# Plotting
temperature_timeseries <- ggplot(monthly_temp_stats, aes(x = as.Date(YM), y = Mean)) +
  geom_line(aes(color = Mean), size = 0.5) +
  geom_smooth(method = "lm", se = FALSE, color = "#CD3333", size=0.5, alpha = .5) +
  scale_color_gradient(low = "yellow", high = "#CD3333", limits = c(10, 25), breaks = seq(10, 25, by = 5), name = "Temp") +
  scale_x_date(date_breaks = "10 years", date_labels = "%Y") +
  scale_y_continuous(limits = c(10, 25), breaks = seq(10, 25, by = 5)) +
  theme_minimal() +
  theme(text = element_text(family = "Times New Roman"),
        axis.title.y = element_text(size = 10, face = "bold"),
        axis.text.y = element_text(size = 8),
        axis.title.x = element_text(size = 10, face = "bold"),
        legend.title = element_text(face = "bold")) +
  labs(y = "Sea Surface Temperature (°C)", x="Date", color = "Temp (°C)", 
       title = "", subtitle = "")

print(temperature_timeseries)
```

```{r}
# Read and preprocess data
newportbeach.pH <- read_csv(here("Data", "Site_Data", "Newport_pH_2005-2024.csv"))[-1,]

filtered.newportbeach.pH <- newportbeach.pH %>%
  mutate(pH = sea_water_ph_reported_on_total_scale_salinity_corrected,
         time = as.POSIXct(time, format = "%Y-%m-%dT%H:%M:%SZ", tz = "UTC"), date=as.Date(time)) %>%
  filter(sea_water_ph_reported_on_total_scale_salinity_corrected_qc_agg %in% 1) %>% 
  select(date, time, pH)

filtered.newportbeach.pH <- filtered.newportbeach.pH %>%
  arrange(time) %>% 
  mutate(gap = c(0, diff(time) > hours(6)),  # Create a logical vector where TRUE indicates a gap
         group = cumsum(gap))

# Calculate 3-hour mean and confidence intervals
six_hour_ph_stats <- filtered.newportbeach.pH %>%
  mutate(SixHourInterval = floor_date(time, "6 hours")) %>%
  group_by(group, SixHourInterval) %>%
  summarise(
    Mean = mean(pH, na.rm = TRUE),
    SD = sd(pH, na.rm = TRUE),
    N = n(),
    SE = SD / sqrt(N),
    Lower_95CI = Mean - qt(0.975, N - 1) * SE,
    Upper_95CI = Mean + qt(0.975, N - 1) * SE
  ) %>%
  ungroup() %>%  # Ungroup for plotting
  na.omit()  # Ensure no NAs remain

# Calculate the overall mean pH
overall_mean_ph <- mean(filtered.newportbeach.pH$pH, na.rm = TRUE)
print(paste("Overall mean pH:", round(overall_mean_ph, 2)))

# pH plot with IQR lines and overall mean
pH_timeseries <- ggplot(six_hour_ph_stats, aes(x = SixHourInterval, y = Mean, group=group)) +
  geom_line(aes(color = Mean), size = 0.5) +
  geom_hline(yintercept = overall_mean_ph, linetype = "dashed", color = "darkcyan", size = 0.5,
             alpha=0.5) +
  scale_color_gradient(low = "cyan3", high = "darkcyan", limits = c(7.6, 8.6), breaks = seq(7.6, 8.6, by = 0.2), name = "pH") +
  scale_x_datetime(date_breaks = "1 year", date_labels = "%b %Y") +
  scale_y_continuous(limits = c(7.6, 8.6), breaks = seq(7.6, 8.6, by = 0.2)) +
  theme_minimal() +
  theme(text = element_text(family = "Times New Roman"),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 8),
        legend.title = element_text(face = "bold")) +
  labs(x = "Date", y = "Mean Sea Water pH", title = "", subtitle = "")

print(pH_timeseries)
```

```{r}
# Combine the plots vertically
combined_timeseries <- temperature_timeseries / pH_timeseries 
print(combined_timeseries)

# Save the combined plot
ggsave("stacked_timeseries.png", combined_timeseries, width = 8, height = 5, dpi = 1200)
```

```{r}

# Read the CSV file
newport.temp <- read_csv(here("Data", "Site_Data", "NewportBeach_TEMP_1924-2023.csv"))

# Filter data using TEMP_FLAG 
# 0 = good data, 5 = data from another source, 6 = data from a different site
# NaN is used to indicate historical/missing data
filtered_temp_data <- newport.temp %>%
  filter(is.na(TEMP_FLAG) | TEMP_FLAG %in% c(0, 5, 6)) %>%
  filter(SURF_TEMP_C >= 9 & SURF_TEMP_C <= 26) %>%
  mutate(DATE = as.Date(paste(YEAR, MONTH, DAY, sep = "-")))

# Calculate monthly statistics 
monthly_temp_stats <- filtered_temp_data %>%
  mutate(YM = as.yearmon(DATE)) %>%
  group_by(YM) %>%
  summarise(
    Mean = mean(SURF_TEMP_C, na.rm = TRUE),
    SD = sd(SURF_TEMP_C, na.rm = TRUE),
    Min = min(SURF_TEMP_C, na.rm = TRUE),
    Max = max(SURF_TEMP_C, na.rm = TRUE),
    N = n(),
    SE = SD / sqrt(N),
    Lower_95CI = Mean - qt(0.975, N - 1) * SE,
    Upper_95CI = Mean + qt(0.975, N - 1) * SE) %>%
  arrange(YM)

# Convert 'YM' to a Date object outside ggplot
monthly_temp_stats <- monthly_temp_stats %>%
  mutate(Date = as.Date(as.yearmon(YM))) %>% 
  arrange(YM)

# Create a YearDecimal column from the Date
monthly_temp_stats$YearDecimal <- year(monthly_temp_stats$Date) +
                                  (yday(monthly_temp_stats$Date) - 1) / (ifelse(leap_year(year(monthly_temp_stats$Date)), 366, 365))

# Fit a GLS model with an AR(3) correlation structure to the monthly data
gls_model <- gls(Mean ~ YearDecimal, data = monthly_temp_stats,
                 correlation = corARMA(p = 3), method = "ML")

# Extract coefficients for slope (change per year) and its standard error
coeffs <- summary(gls_model)$tTable
slope <- coeffs["YearDecimal", "Value"]
slope_se <- coeffs["YearDecimal", "Std.Error"]
decadal_change <- slope * 10  # Convert change per year to change per decade
decadal_change_se <- slope_se * 10  # Standard error for decadal change

# p-value for the slope
slope_pval <- coeffs["YearDecimal", "p-value"]

#print the slope, standard error, and p-value
print(paste("Slope:", round(slope, 4)))
print(paste("Standard Error:", round(slope_se, 4)))
print(paste("Decadal Change:", round(decadal_change, 4)))
print(paste("Standard Error for Decadal Change:", round(decadal_change_se, 4)))
print(paste("P-value for Slope:", round(slope_pval, 4)))
```

# SST Climatological Monthly Means and Standard Deviations

```{r}

# Read the CSV file
newport.temp <- read_csv(here("Data", "Site_Data", "NewportBeach_TEMP_1924-2023.csv"))

# Filter data using TEMP_FLAG 
# 0 = good data, 5 = data from another source, 6 = data from a different site
# NaN is used to indicate historical/missing data
filtered_temp_data <- newport.temp %>%
  filter(is.na(TEMP_FLAG) | TEMP_FLAG %in% c(0, 5, 6)) %>%
  filter(SURF_TEMP_C >= 9 & SURF_TEMP_C <= 26) %>%
  mutate(DATE = as.Date(paste(YEAR, MONTH, DAY, sep = "-")))

# Calculate monthly statistics 
monthly_temp_stats <- filtered_temp_data %>%
  mutate(YM = as.yearmon(DATE)) %>%
  group_by(YM) %>%
  summarise(
    Mean = mean(SURF_TEMP_C, na.rm = TRUE),
    SD = sd(SURF_TEMP_C, na.rm = TRUE),
    Min = min(SURF_TEMP_C, na.rm = TRUE),
    Max = max(SURF_TEMP_C, na.rm = TRUE),
    N = n(),
    SE = SD / sqrt(N),
    Lower_95CI = Mean - qt(0.975, N - 1) * SE,
    Upper_95CI = Mean + qt(0.975, N - 1) * SE) %>%
  arrange(YM)

# Assuming 'monthly_temp_stats' has a 'Date' column
monthly_temp_stats <- monthly_temp_stats %>%
  mutate(
    Month = month(Date, label = TRUE, abbr = TRUE),  # Extract month with abbreviation
    Decade = floor(year(Date) / 10) * 10  # Calculate the decade
  )

# Calculate the average temperature and its standard error for each month in each decade
avg_temp_by_month_decade <- monthly_temp_stats %>%
  group_by(Month, Decade) %>%
  summarise(
    AvgTemp = mean(Mean, na.rm = TRUE),
    StdErr = sd(Mean, na.rm = TRUE) / sqrt(n())
  ) %>%
  ungroup()

# Ensure 'Month' is an ordered factor
avg_temp_by_month_decade$Month <- factor(avg_temp_by_month_decade$Month, levels = month.abb)

# Generate a heat color palette with 12 colors
palette_heat <- rev(palette_heat)

# Display the generated color palette
palette_heat

p3 <- ggplot(avg_temp_by_month_decade, aes(x = Month, y = AvgTemp, color = as.factor(Decade), group = Decade)) +
  geom_line() +
  geom_point() +
  geom_errorbar(aes(ymin = AvgTemp - StdErr, ymax = AvgTemp + StdErr), width = 0.2) +  # Adding error bars
  scale_color_manual(values = palette_heat, name="Decade") +  # Use manual scale for custom color palette
  theme_minimal() +
  theme(axis.text.x = element_text(hjust = 1),
        text = element_text(family = "Times New Roman"),
        axis.title.x = element_text(size = 12, face = "bold"),
        axis.title.y = element_text(size = 12, face = "bold"),
        legend.title = element_text(face = "bold", size = 12)) +
  labs(y = "Average Monthly SST (°C)", x="Month")

print(p3)
```


# Intertidal SST logger PISCO (Point Fermin, Los Angeles, CA)

Citation: 
Multi-Agency Rocky Intertidal Network (MARINe), Partnership Interdisciplinary Studies Coastal Oceans for of (PISCO), & Jennifer Burnaford. (2023). MARINe/PISCO: Intertidal: site temperature data: Point Fermin, California (IPTFXX). PISCO MN. doi:10.6085/AA/IPTFXX_XXXITV2XMSR01_20220130.50.1.

```{r}

# Reading the temperature data (adjust the path and column names as per your file)
temp_data <- read.table(here::here("Data", "Site_Data", "Long_Beach_Intertidal_SST_Temp_2022"), header = TRUE)

temp_data <- temp_data %>%
  mutate(datetime = as.POSIXct(paste(date, time), format = "%Y-%m-%d %H:%M:%S", tz = "UTC")) %>%
  select(-date, -time) %>%
  filter(!grepl("1|2|9", flag))

# Read the tide data (and the tide data at high and low tides in order to begin labeling tide fluctuations, California is a semi diurnal tide with tides lasting approx 6 hours and 12.5 minutes)
hourly_tide_data<- read_csv(here::here("Data", "Site_Data", "Long_Beach_CA_Hourly_Tides.csv"))
hourly_tide_data <- hourly_tide_data %>%
  mutate(datetime = as.POSIXct(paste(Date, format(`Time (GMT)`, format = "%H:%M:%S")), format = "%Y-%m-%d %H:%M:%S", tz = "UTC")) %>% # Drop the original 'Date' and 'Time (GMT)' columns
  select(datetime, Predicted = `Predicted (m)`, Verified = `Verified (m)`) 

# Filter the hourly tide data to match the temperature data range
hourly_tide_data_filtered <- hourly_tide_data %>%
  filter(datetime >= min(temp_data$datetime) & datetime <= max(temp_data$datetime))

# Label the hourly tide data as high or low based on Verified values
hourly_tide_data <- hourly_tide_data %>%
  mutate(Tide = ifelse(Verified > 0, 'High', 'Low'))

joined_data <- temp_data %>%
  left_join(hourly_tide_data, by = "datetime") %>%
  mutate(Verified = zoo::na.approx(Verified, na.rm = FALSE)) %>%
  mutate(Tide = ifelse(Verified > 0, 'High', 'Low')) %>%
  select(-Predicted, -flag, datetime, tempc, Tide, -Verified) %>%
  mutate(Tide = if_else(row_number() <= 3, "Low", Tide))

# Determine day and night periods
joined_data <- joined_data %>%
  mutate(day = getSunlightTimes(as.Date(datetime), lat = 33.705, lon = -118.293, tz = "UTC")$sunrise < datetime & 
            datetime < getSunlightTimes(as.Date(datetime), lat = 33.705, lon = -118.293, tz = "UTC")$sunset) %>%
  mutate(time_of_day = ifelse(day, "Day", "Night")) %>%
  select(-day, -yearday)

# Generate summary statistics for each condition

# Separate temperature data into likely air and water temperatures based on tide categories
air_temperatures <- joined_data %>% 
  filter(Tide == 'Low') %>%
  select(datetime, tempc)

water_temperatures <- joined_data %>% 
  filter(Tide == 'High') %>%
  select(datetime, tempc)

# Generating basic statistics for air and water temperatures
air_stats <- summary(air_temperatures$tempc)
water_stats <- summary(water_temperatures$tempc)

# Separate temperature data into day and night temperatures
day_temperatures <- joined_data %>%
  filter(time_of_day == "Day")

night_temperatures <- joined_data %>%
  filter(time_of_day == "Night")

# Calculate statistics for day and night temperatures
day_stats <- summary(day_temperatures$tempc)
night_stats <- summary(night_temperatures$tempc)

# Day High Tide
day_high_stats <- joined_data %>%
  filter(time_of_day == "Day", Tide == "High") %>%
  summarise(Mean = mean(tempc, na.rm = TRUE), Max = max(tempc, na.rm = TRUE), Min = min(tempc, na.rm = TRUE))

# Day Low Tide
day_low_stats <- joined_data %>%
  filter(time_of_day == "Day", Tide == "Low") %>%
  summarise(Mean = mean(tempc, na.rm = TRUE), Max = max(tempc, na.rm = TRUE), Min = min(tempc, na.rm = TRUE))

# Night High Tide
night_high_stats <- joined_data %>%
  filter(time_of_day == "Night", Tide == "High") %>%
  summarise(Mean = mean(tempc, na.rm = TRUE), Max = max(tempc, na.rm = TRUE), Min = min(tempc, na.rm = TRUE))

# Night Low Tide
night_low_stats <- joined_data %>%
  filter(time_of_day == "Night", Tide == "Low") %>%
  summarise(Mean = mean(tempc, na.rm = TRUE), Max = max(tempc, na.rm = TRUE), Min = min(tempc, na.rm = TRUE))

# Print statistics
print("Day High Tide Stats")
print(day_high_stats)

print("Day Low Tide Stats")
print(day_low_stats)

print("Night High Tide Stats")
print(night_high_stats)

print("Night Low Tide Stats")
print(night_low_stats)

print("Air Temperature Statistics")
print(air_stats)

print("Water Temperature Statistics")
print(water_stats)

print("Day Temperature Statistics")
print(day_stats)

print("Night Temperature Statistics")
print(day_stats)

# Plotting the data
ggplot(air_temperatures, aes(x = datetime, y = tempc)) +
  geom_line(color = "darkgreen") +
  labs(title = "Air Temperatures Over Time", x = "Datetime", y = "Temperature (°C)")

ggplot(water_temperatures, aes(x = datetime, y = tempc)) +
  geom_line(color = "cyan2") +
  labs(title = "Water Temperatures Over Time", x = "Datetime", y = "Temperature (°C)")


ggplot(joined_data %>% filter(time_of_day == "Day"), aes(x = datetime, y = tempc, group = Tide)) +
  geom_line(aes(color = Tide), na.rm = FALSE) +  # Keeping NA values
  labs(title = "Daytime Temperatures with Tide Information", x = "Datetime", y = "Temperature (°C)") +
  scale_color_manual(values = c("High" = "cyan2", "Low" = "darkgreen")) +
  theme_minimal()

ggplot(joined_data %>% filter(time_of_day == "Night"), aes(x = datetime, y = tempc, group = Tide)) +
  geom_line(aes(color = Tide), na.rm = FALSE) +
  labs(title = "Nighttime Temperatures with Tide Information", x = "Datetime", y = "Temperature (°C)") +
  scale_color_manual(values = c("High" = "cyan2", "Low" = "darkgreen")) +
  theme_minimal()

# Assuming 'datetime' is your timestamp column
# Filter data for August and September
aug_sep_data <- joined_data %>%
  filter(month(datetime) %in% c(8, 9))

# Calculate average air and water temperatures for August and September
avg_air_temp <- aug_sep_data %>%
  filter(Tide == 'Low') %>%
  summarise(avg_air_temp = mean(tempc, na.rm = TRUE), Max = max(tempc, na.rm = TRUE), Min = min(tempc, na.rm = TRUE))

avg_water_temp <- aug_sep_data %>%
  filter(Tide == 'High') %>%
  summarise(avg_water_temp = mean(tempc, na.rm = TRUE), Max = max(tempc, na.rm = TRUE), Min = min(tempc, na.rm = TRUE))

# Print average temperatures
print("Average Air Temperature for August and September:")
print(avg_air_temp)

print("Average Water Temperature for August and September:")
print(avg_water_temp)


```

```{r}

# Reading in data
file_path <- here::here("Data", "Site_Data", "PISCO_Point_Fermin_Temp_2022")
data <- read.table(file_path, header = TRUE)

# Convert the "date" column to a date format
data <- data %>% 
  mutate(date = as.Date(date, format = "%Y-%m-%d")) 

# Assuming your data frame is named 'data', replace it with your actual data frame name
cleaned_data <- data %>%
  #filter(date >= "2022-08-01" & date <= "2022-09-30") %>%
  mutate(datetime = as.POSIXct(paste(date, time), format = "%Y-%m-%d %H:%M:%S"),
         hour = hour(datetime),
         month = month(datetime)) %>%
  select(datetime, date, time, tempc, hour) %>%
  na.omit()

# Calculate average temperature per hour
hourly_avg <- cleaned_data %>%
  group_by(hour, date) %>%
  summarise(avg_tempc = mean(tempc))

# Define the location info
location_info <- "Data: Partnership Interdisciplinary Studies Coastal Oceans (PISCO)\n Multi-Agency Rocky Intertidal Network (MARINe),\n Point Fermin, CA (33°42'24.49''N 118°17'9.57''W)"

# Define color gradient from yellow to orange
color_palette <- colorRampPalette(c("yellow", "orange"))

# Create the plot
intertidal_time_series_plot <- ggplot(hourly_avg, aes(x = date, y = avg_tempc)) +
  geom_line(aes(color =  avg_tempc)) +
    scale_color_gradient(low = "yellow", high = "orange", name = "Mean Temp (°C)") +  # Set color scale
  stat_summary(fun = mean, geom = "line", aes(group = 1), color = "red", size = 0.5, alpha= 0.5) +
  labs(title = "Intertidal Temperature Timeseries (Jan-2022 - Nov-2022)",
       x = "Month",
       y = "Mean Hourly Temperature (°C)",
       subtitle = location_info)  +
  scale_x_date(date_breaks = "1 month", date_labels = "%b", limits = as.Date(c("2022-01-31", "2022-11-06"))) +  # Set x-axis breaks and limits
  theme_minimal() +
  theme(
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5), # Centering the title
    plot.subtitle = element_text(hjust = 0.5)
  )

# Print the plot
print(intertidal_time_series_plot)

# Save the plot as a PNG file
ggsave(filename = here::here("Images", "intertidal_timeseries_plot.png"), plot = intertidal_time_series_plot, width = 10, height = 6)

```

```{r}

experiment_months_data <- data %>%
  filter(date >= "2022-08-01" & date <= "2022-09-30") %>%
  mutate(datetime = as.POSIXct(paste(date, time), format = "%Y-%m-%d %H:%M:%S"),
         hour = hour(datetime),
         month = month(datetime)) %>%
  select(datetime, date, time, tempc, hour) %>%
  na.omit()

# Define color gradient from yellow to orange
color_palette <- colorRampPalette(c("yellow", "orange"))

# Plot the time series
experiment_pH_timeseries_plot<-ggplot(experiment_months_data, aes(x = datetime, y = tempc)) +
  stat_summary(fun = mean, geom = "line", aes(group = 1, color = tempc), size = 0.5) +  # Plotting average per hour
  scale_color_gradient(low = "yellow", high = "orange", name = "Temp (°C)") +  # Set color scale
  labs(title = "Intertidal Temperature Timeseries (Aug-2022 - Sep-2022)",
       x = "Month",
       y = "Temperature (°C)",
       subtitle = location_info)  +
  theme_minimal() +
  theme(
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5), # Centering the title
    plot.subtitle = element_text(hjust = 0.5)
  )

# Save the plot as a PNG file
ggsave(filename = here::here("Images", "experiment_pH_timeseries_plot.png"), plot = experiment_pH_timeseries_plot, width = 10, height = 6)

```




